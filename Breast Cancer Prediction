import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer

# Load data
data = load_breast_cancer()
X = data.data
y = data.target
feature_names = data.feature_names

# Create DataFrame
df = pd.DataFrame(X, columns=feature_names)
df['target'] = y

# Display summary statistics
print(df.describe())

# Check for missing values
print("Missing values:\n", df.isnull().sum())

# Class distribution
print("Class distribution:\n", df['target'].value_counts())

# Visualize data distributions and correlations
sns.pairplot(df, hue="target", diag_kind='kde')
plt.show()

# Correlation matrix heatmap
plt.figure(figsize=(16, 12))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Matrix")
plt.show()
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Initialize models
log_reg = LogisticRegression()
random_forest = RandomForestClassifier(random_state=42)

# Train the models
log_reg.fit(X_train, y_train)
random_forest.fit(X_train, y_train)
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score, roc_curve

# Evaluate Logistic Regression
y_pred_log_reg = log_reg.predict(X_test)
print("Logistic Regression Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_log_reg))
print("Precision:", precision_score(y_test, y_pred_log_reg))
print("Recall:", recall_score(y_test, y_pred_log_reg))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_log_reg))
print("Classification Report:\n", classification_report(y_test, y_pred_log_reg))

# ROC Curve for Logistic Regression
fpr, tpr, _ = roc_curve(y_test, log_reg.predict_proba(X_test)[:, 1])
plt.plot(fpr, tpr, label=f"Logistic Regression AUC = {roc_auc_score(y_test, y_pred_log_reg):.3f}")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Logistic Regression")
plt.legend()
plt.show()

# Evaluate Random Forest using cross-validation
from sklearn.model_selection import cross_val_score

scores = cross_val_score(log_reg, X, y, cv=5)
print("Logistic Regression Cross-Validation Accuracy:", scores)
print("Mean Accuracy:", scores.mean())
import joblib

# Save models and scaler
joblib.dump(log_reg, "breast_cancer_log_reg_model.pkl")
joblib.dump(scaler, "scaler.pkl")

# Load the saved model and scaler
log_reg_model = joblib.load("breast_cancer_log_reg_model.pkl")
scaler = joblib.load("scaler.pkl")
import streamlit as st
import numpy as np

# Streamlit app title
st.title("Breast Cancer Prediction Model")
st.write("Input the required parameters to get a prediction.")

# Streamlit inputs for features
feature_inputs = []
for feature in feature_names:
    feature_value = st.number_input(f"{feature}", value=0.0)
    feature_inputs.append(feature_value)

# Prediction button
if st.button("Predict"):
    sample = np.array(feature_inputs).reshape(1, -1)
    sample_scaled = scaler.transform(sample)
    prediction = log_reg_model.predict(sample_scaled)
    prediction_label = "Malignant" if prediction[0] == 1 else "Benign"
    st.write("Prediction:", prediction_label)



