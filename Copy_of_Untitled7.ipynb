{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZRH8G8hNcBoVMketYUxAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratiksha377/Breast-Cancer-Prediction-/blob/main/Copy_of_Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6kUtUakayb7c",
        "outputId": "019004c9-a4ec-4725-a67e-f320843006c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.17.1 in /usr/local/lib/python3.11/dist-packages (0.17.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.1) (2.32.3)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.1) (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.1) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.1) (0.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1->torchtext==0.17.1) (2.2.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.1) (2.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchtext==0.17.1) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.1) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.1->torchtext==0.17.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.1->torchtext==0.17.1) (1.3.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.17.1\n",
        "!pip install sacrebleu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall --quiet\n",
        "import os\n",
        "os.kill(os.getpid(), 9)  # Restart the runtime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YYpynfCW1zaY",
        "outputId": "51d39245-2225-4074-f030-ebe4b2e2626c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sacrebleu\n"
      ],
      "metadata": {
        "id": "QFLwzM6BzAXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/pratikshasarma40.tsv', sep='\\t')  # Replace with your CSV path\n",
        "df = df[['English_Translation', 'Assamese_Sentence']].dropna()\n",
        "display(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ucY2xnmY1jb5",
        "outputId": "2b0ad0d3-b61b-4da1-91f3-d15236966bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 English_Translation  \\\n",
              "0  Moreover, Naba Kumar Sarania has expressed the...   \n",
              "1  Kuladhar Saikia was an IPS officer of 1985 batch.   \n",
              "2  Like every year, this time too, the 55th Devi ...   \n",
              "3  The moment he came to know about the failure f...   \n",
              "4  This is how the laddu is preparing for the Lok...   \n",
              "\n",
              "                                   Assamese_Sentence  \n",
              "0  তদুপৰি এইবেলিও পূৰ্বৰ দৰেই তেওঁ বিপুল ভোটত জয়ী...  \n",
              "1       ১৯৮৫ বেটছৰ আই পি এছ বিষয়া আছিল কুলধৰ শইকীয়া।  \n",
              "2  প্ৰতিবছৰৰ দৰে এইবাৰো বহাগ মাহৰ কৃষ্ণ পক্ষৰ প্ৰ...  \n",
              "3  ইছৰ’ৰ অধ্যক্ষৰ পৰা এই বিজুতিৰ বিষয়ে অৱগত হোৱাৰ...  \n",
              "4  বৃহস্পতিবাৰে ঘোষণা হ’ব লগা লোকসভা নিৰ্বাচনৰ ফল...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf02c76d-5f5c-4578-b3b1-a4a51d716724\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English_Translation</th>\n",
              "      <th>Assamese_Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Moreover, Naba Kumar Sarania has expressed the...</td>\n",
              "      <td>তদুপৰি এইবেলিও পূৰ্বৰ দৰেই তেওঁ বিপুল ভোটত জয়ী...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kuladhar Saikia was an IPS officer of 1985 batch.</td>\n",
              "      <td>১৯৮৫ বেটছৰ আই পি এছ বিষয়া আছিল কুলধৰ শইকীয়া।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Like every year, this time too, the 55th Devi ...</td>\n",
              "      <td>প্ৰতিবছৰৰ দৰে এইবাৰো বহাগ মাহৰ কৃষ্ণ পক্ষৰ প্ৰ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The moment he came to know about the failure f...</td>\n",
              "      <td>ইছৰ’ৰ অধ্যক্ষৰ পৰা এই বিজুতিৰ বিষয়ে অৱগত হোৱাৰ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is how the laddu is preparing for the Lok...</td>\n",
              "      <td>বৃহস্পতিবাৰে ঘোষণা হ’ব লগা লোকসভা নিৰ্বাচনৰ ফল...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf02c76d-5f5c-4578-b3b1-a4a51d716724')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf02c76d-5f5c-4578-b3b1-a4a51d716724 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf02c76d-5f5c-4578-b3b1-a4a51d716724');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c48ad3a2-399d-4d5d-a72e-b27842a21c5f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c48ad3a2-399d-4d5d-a72e-b27842a21c5f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c48ad3a2-399d-4d5d-a72e-b27842a21c5f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"English_Translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Kuladhar Saikia was an IPS officer of 1985 batch.\",\n          \"This is how the laddu is preparing for the Lok Sabha election results to be announced on Thursday.\",\n          \"Like every year, this time too, the 55th Devi Charantala Mela is held in the West Garo Hills district of the neighbouring state of Meghalaya on the first Tuesday of the Krishna Paksha in the month of Bahag.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Assamese_Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u09e7\\u09ef\\u09ee\\u09eb \\u09ac\\u09c7\\u099f\\u099b\\u09f0 \\u0986\\u0987 \\u09aa\\u09bf \\u098f\\u099b \\u09ac\\u09bf\\u09b7\\u09df\\u09be \\u0986\\u099b\\u09bf\\u09b2 \\u0995\\u09c1\\u09b2\\u09a7\\u09f0 \\u09b6\\u0987\\u0995\\u09c0\\u09df\\u09be\\u0964\",\n          \"\\u09ac\\u09c3\\u09b9\\u09b8\\u09cd\\u09aa\\u09a4\\u09bf\\u09ac\\u09be\\u09f0\\u09c7 \\u0998\\u09cb\\u09b7\\u09a3\\u09be \\u09b9\\u2019\\u09ac \\u09b2\\u0997\\u09be \\u09b2\\u09cb\\u0995\\u09b8\\u09ad\\u09be \\u09a8\\u09bf\\u09f0\\u09cd\\u09ac\\u09be\\u099a\\u09a8\\u09f0 \\u09ab\\u09b2\\u09be\\u09ab\\u09b2\\u09f0 \\u09ac\\u09be\\u09ac\\u09c7 \\u09aa\\u09cd\\u09f0\\u09b8\\u09cd\\u09a4\\u09c1\\u09a4 \\u0995\\u09f0\\u09bf\\u099b\\u09c7 \\u098f\\u09a8\\u09c7\\u09a6\\u09f0\\u09c7 \\u09b2\\u09be\\u09a1\\u09bc\\u09c1\\u0964\",\n          \"\\u09aa\\u09cd\\u09f0\\u09a4\\u09bf\\u09ac\\u099b\\u09f0\\u09f0 \\u09a6\\u09f0\\u09c7 \\u098f\\u0987\\u09ac\\u09be\\u09f0\\u09cb \\u09ac\\u09b9\\u09be\\u0997 \\u09ae\\u09be\\u09b9\\u09f0 \\u0995\\u09c3\\u09b7\\u09cd\\u09a3 \\u09aa\\u0995\\u09cd\\u09b7\\u09f0 \\u09aa\\u09cd\\u09f0\\u09a5\\u09ae\\u099f\\u09cb \\u09ae\\u0999\\u09b2\\u09ac\\u09be\\u09f0\\u09f0 \\u09a6\\u09bf\\u09a8\\u09be \\u099a\\u09c1\\u09ac\\u09c1\\u09f0\\u09c0\\u09df\\u09be \\u09f0\\u09be\\u099c\\u09cd\\u09af \\u09ae\\u09c7\\u0998\\u09be\\u09b2\\u09df\\u09f0 \\u09aa\\u09b6\\u09cd\\u099a\\u09bf\\u09ae \\u0997\\u09be\\u09f0\\u09cb \\u09aa\\u09be\\u09b9\\u09be\\u09f0 \\u099c\\u09bf\\u09b2\\u09be\\u09a4 \\u0985\\u09a8\\u09c1\\u09b7\\u09cd\\u09a0\\u09bf\\u09a4 \\u09b9\\u09df \\u09eb\\u09eb \\u09a4\\u09ae \\u09a6\\u09c7\\u09f1\\u09c0 \\u099a\\u09be\\u09f0\\u09a3\\u09a4\\u09b2\\u09be \\u09ae\\u09c7\\u09b2\\u09be\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_en(sentence):\n",
        "    return sentence.lower().strip().split()\n",
        "\n",
        "def tokenize_as(sentence):\n",
        "    return sentence.strip().split()\n"
      ],
      "metadata": {
        "id": "J1t9Vgqd4A9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data, tokenizer):\n",
        "    for sentence in data:\n",
        "        yield tokenizer(sentence)\n",
        "\n",
        "SRC_VOCAB = build_vocab_from_iterator(yield_tokens(df['English_Translation'], tokenize_en), specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"])\n",
        "TGT_VOCAB = build_vocab_from_iterator(yield_tokens(df['Assamese_Sentence'], tokenize_as), specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"])\n",
        "\n",
        "SRC_VOCAB.set_default_index(SRC_VOCAB[\"<unk>\"])\n",
        "TGT_VOCAB.set_default_index(TGT_VOCAB[\"<unk>\"])\n",
        "SRC_itos = SRC_VOCAB.get_itos()\n",
        "TGT_itos = TGT_VOCAB.get_itos()\n",
        "\n",
        "SRC_stoi = SRC_VOCAB.get_stoi()\n",
        "TGT_stoi = TGT_VOCAB.get_stoi()\n"
      ],
      "metadata": {
        "id": "zWdm9E9o4HD7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "740fb5a2-c153-454c-9214-6f027bd31027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'build_vocab_from_iterator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-3049456261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mSRC_VOCAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'English_Translation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<sos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mTGT_VOCAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Assamese_Sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<sos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_vocab_from_iterator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_pair(src, tgt):\n",
        "    src_tensor = [SRC_VOCAB[\"<sos>\"]] + [SRC_VOCAB[token] for token in tokenize_en(src)] + [SRC_VOCAB[\"<eos>\"]]\n",
        "    tgt_tensor = [TGT_VOCAB[\"<sos>\"]] + [TGT_VOCAB[token] for token in tokenize_as(tgt)] + [TGT_VOCAB[\"<eos>\"]]\n",
        "    return torch.tensor(src_tensor), torch.tensor(tgt_tensor)\n",
        "\n",
        "pairs = [process_pair(en, asam) for en, asam in zip(df['English_Translation'], df['Assamese_Sentence'])]\n",
        "train_data, test_data = train_test_split(pairs, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "e3anJ8-l4jpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=SRC_VOCAB[\"<pad>\"])\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=TGT_VOCAB[\"<pad>\"])\n",
        "    return src_batch.transpose(0, 1), tgt_batch.transpose(0, 1)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "KI-wumor4m-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, encoder_outputs.shape[1], 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.attention = attention\n",
        "        self.lstm = nn.LSTM(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.embedding(input)\n",
        "        attn_weights = self.attention(hidden[-1], encoder_outputs).unsqueeze(1)\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)\n",
        "        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
        "        prediction = self.fc(torch.cat((output.squeeze(1), context.squeeze(1)), dim=1))\n",
        "        return prediction, hidden, cell\n"
      ],
      "metadata": {
        "id": "z6wIDnlq4pl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size, tgt_len = tgt.shape\n",
        "        tgt_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(src.device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        input = tgt[:, 0]\n",
        "\n",
        "        for t in range(1, tgt_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            input = tgt[:, t] if teacher_force else output.argmax(1)\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "wGuFEWOo4skS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 38\n",
        "\n",
        "INPUT_DIM = len(SRC_VOCAB)\n",
        "OUTPUT_DIM = len(TGT_VOCAB)\n",
        "EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "attn = Attention(HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, attn)\n",
        "model = Seq2Seq(enc, dec).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TGT_VOCAB['<pad>'])\n",
        "\n",
        "print(\"🔁 Starting training for 60 epochs...\\n\")\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, tgt in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "        output = output[:, 1:].reshape(-1, output.shape[-1])\n",
        "        tgt = tgt[:, 1:].reshape(-1)\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f\"🟢 Epoch {epoch}/{NUM_EPOCHS} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Optional: Save after training\n",
        "torch.save(model.state_dict(), \"eng_to_asam_lstm_attn_60epoch.pth\")\n",
        "print(\"\\n✅ Model saved as 'eng_to_asam_lstm_attn_60epoch.pth'\")\n",
        "\n",
        "from IPython.display import FileLink\n",
        "FileLink(\"eng_to_asam_lstm_attn_60epoch.pth\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "TdSTJUQe4uDI",
        "outputId": "13d3949f-ff2f-48ee-d10b-988c00c3114c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Starting training for 60 epochs...\n",
            "\n",
            "🟢 Epoch 1/38 | Loss: 8.7618\n",
            "🟢 Epoch 2/38 | Loss: 8.0088\n",
            "🟢 Epoch 3/38 | Loss: 7.2276\n",
            "🟢 Epoch 4/38 | Loss: 6.0901\n",
            "🟢 Epoch 5/38 | Loss: 4.8157\n",
            "🟢 Epoch 6/38 | Loss: 3.8211\n",
            "🟢 Epoch 7/38 | Loss: 3.3152\n",
            "🟢 Epoch 8/38 | Loss: 2.9142\n",
            "🟢 Epoch 9/38 | Loss: 2.5354\n",
            "🟢 Epoch 10/38 | Loss: 2.1948\n",
            "🟢 Epoch 11/38 | Loss: 1.8581\n",
            "🟢 Epoch 12/38 | Loss: 1.6100\n",
            "🟢 Epoch 13/38 | Loss: 1.3575\n",
            "🟢 Epoch 14/38 | Loss: 1.1417\n",
            "🟢 Epoch 15/38 | Loss: 0.9247\n",
            "🟢 Epoch 16/38 | Loss: 0.7470\n",
            "🟢 Epoch 17/38 | Loss: 0.5963\n",
            "🟢 Epoch 18/38 | Loss: 0.4670\n",
            "🟢 Epoch 19/38 | Loss: 0.3678\n",
            "🟢 Epoch 20/38 | Loss: 0.2878\n",
            "🟢 Epoch 21/38 | Loss: 0.2337\n",
            "🟢 Epoch 22/38 | Loss: 0.1909\n",
            "🟢 Epoch 23/38 | Loss: 0.1541\n",
            "🟢 Epoch 24/38 | Loss: 0.1277\n",
            "🟢 Epoch 25/38 | Loss: 0.1195\n",
            "🟢 Epoch 26/38 | Loss: 0.1121\n",
            "🟢 Epoch 27/38 | Loss: 0.1066\n",
            "🟢 Epoch 28/38 | Loss: 0.0951\n",
            "🟢 Epoch 29/38 | Loss: 0.0986\n",
            "🟢 Epoch 30/38 | Loss: 0.0982\n",
            "🟢 Epoch 31/38 | Loss: 0.0888\n",
            "🟢 Epoch 32/38 | Loss: 0.0772\n",
            "🟢 Epoch 33/38 | Loss: 0.0673\n",
            "🟢 Epoch 34/38 | Loss: 0.0662\n",
            "🟢 Epoch 35/38 | Loss: 0.0596\n",
            "🟢 Epoch 36/38 | Loss: 0.0625\n",
            "🟢 Epoch 37/38 | Loss: 0.0585\n",
            "🟢 Epoch 38/38 | Loss: 0.0567\n",
            "\n",
            "✅ Model saved as 'eng_to_asam_lstm_attn_60epoch.pth'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/eng_to_asam_lstm_attn_60epoch.pth"
            ],
            "text/html": [
              "<a href='eng_to_asam_lstm_attn_60epoch.pth' target='_blank'>eng_to_asam_lstm_attn_60epoch.pth</a><br>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), \"eng_to_asam_lstm_attn_60epoch.pth\")\n",
        "print(\"✅ Model weights saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmL8eiPGzRP5",
        "outputId": "7ee1519e-7d79-4dcf-a7d8-eb33df513273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model weights saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"eng_to_asam_lstm_attn_60epoch.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hlyqkbXJi9ec",
        "outputId": "3f2a0d59-a3ac-4bc4-89d1-324a9d7c7c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d00ff62f-73f5-4922-96b1-45c6b0bed5b7\", \"eng_to_asam_lstm_attn_60epoch.pth\", 104960794)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "1NWL5sLFy8Ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc91c8dc-febf-40da-8ccb-a670cb65e873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "INPUT_DIM = len(SRC_VOCAB)\n",
        "OUTPUT_DIM = len(TGT_VOCAB)\n",
        "EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "attn = Attention(HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TGT_VOCAB['<pad>'])\n",
        "\n",
        "# 🔁 Train for One Epoch\n",
        "model.train()\n",
        "for src, tgt in train_loader:\n",
        "    src, tgt = src.to(device), tgt.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(src, tgt)\n",
        "    output = output[:, 1:].reshape(-1, output.shape[-1])\n",
        "    tgt = tgt[:, 1:].reshape(-1)\n",
        "    loss = criterion(output, tgt)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f\"\\n✅ Training Complete! Final Loss: {loss.item():.4f}\\n\")\n",
        "\n",
        "# 🔎 Evaluation with Sentence-wise and Overall BLEU\n",
        "model.eval()\n",
        "bleu = BLEU()\n",
        "pred_sentences = []\n",
        "true_sentences = []\n",
        "sentence_bleus = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for src, tgt in test_loader:\n",
        "        src = src.to(device)\n",
        "        encoder_outputs, hidden, cell = model.encoder(src)\n",
        "        input = torch.tensor([TGT_VOCAB['<sos>']] * src.size(0)).to(device)\n",
        "\n",
        "        preds = []\n",
        "        for _ in range(30):\n",
        "            output, hidden, cell = model.decoder(input, hidden, cell, encoder_outputs)\n",
        "            top1 = output.argmax(1)\n",
        "            preds.append(top1.item())\n",
        "            input = top1\n",
        "            if top1.item() == TGT_VOCAB['<eos>']:\n",
        "                break\n",
        "\n",
        "        pred_tokens = [TGT_VOCAB.get_itos()[idx] for idx in preds if idx not in [TGT_VOCAB['<pad>'], TGT_VOCAB['<sos>'], TGT_VOCAB['<eos>']]]\n",
        "        true_tokens = [TGT_VOCAB.get_itos()[idx.item()] for idx in tgt[0] if idx.item() not in [TGT_VOCAB['<pad>'], TGT_VOCAB['<sos>'], TGT_VOCAB['<eos>']]]\n",
        "\n",
        "        pred_sentence = \" \".join(pred_tokens)\n",
        "        true_sentence = \" \".join(true_tokens)\n",
        "\n",
        "        pred_sentences.append(pred_sentence)\n",
        "        true_sentences.append(true_sentence)\n",
        "\n",
        "        sentence_bleu = bleu.sentence_score(pred_sentence, [true_sentence]).score\n",
        "        sentence_bleus.append(sentence_bleu)\n",
        "\n",
        "        print(f\"🔵 Ground Truth   : {true_sentence}\")\n",
        "        print(f\"🟢 Prediction     : {pred_sentence}\")\n",
        "        print(f\"🎯 Sentence BLEU  : {sentence_bleu:.2f}\\n\")\n",
        "\n",
        "# 🌐 Corpus BLEU\n",
        "corpus_bleu = bleu.corpus_score(pred_sentences, [true_sentences])\n",
        "print(\"🌟 Model BLEU Score:\", f\"{corpus_bleu.score:.2f}\")\n"
      ],
      "metadata": {
        "id": "xeQM5Nqj4uS-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "25e8dce4-b20b-480d-bb64-64150133a5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SRC_VOCAB' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3240921534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msacrebleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBLEU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mINPUT_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC_VOCAB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mOUTPUT_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTGT_VOCAB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mEMB_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SRC_VOCAB' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "580d8f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de00be79-0568-4746-957d-83e8410db226"
      },
      "source": [
        "# Re-initialize architecture exactly like before\n",
        "attn = Attention(HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, attn)\n",
        "model = Seq2Seq(enc, dec).to(device)\n",
        "\n",
        "# Load saved weights\n",
        "model.load_state_dict(torch.load(\"eng_to_asam_lstm_attn_60epoch.pth\"))\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(23757, 128)\n",
              "    (lstm): LSTM(128, 256, batch_first=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(34343, 128)\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
              "    )\n",
              "    (lstm): LSTM(384, 256, batch_first=True)\n",
              "    (fc): Linear(in_features=512, out_features=34343, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_VOCAB = build_vocab(df['src_tokens'])\n",
        "TGT_VOCAB = build_vocab(df['tgt_tokens'])\n",
        "\n",
        "SRC_itos = {i: s for s, i in SRC_VOCAB.items()}\n",
        "TGT_itos = {i: s for s, i in TGT_VOCAB.items()}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "b-nG-CIlyKIV",
        "outputId": "7bfab45c-0e1a-4596-d3bd-17593c4f3bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'build_vocab' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-4016335556.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSRC_VOCAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTGT_VOCAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tgt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSRC_itos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSRC_VOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTGT_itos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTGT_VOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_vocab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, src_vocab, tgt_vocab, tgt_itos, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize and convert to indices\n",
        "    tokens = sentence.lower().strip().split()\n",
        "    src_ids = [src_vocab.get(token, src_vocab['<unk>']) for token in tokens]\n",
        "    src_tensor = torch.tensor(src_ids).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src_tensor)\n",
        "        input_token = torch.tensor([tgt_vocab['<sos>']]).to(device)\n",
        "        result_ids = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            output, hidden, cell = model.decoder(input_token, hidden, cell, encoder_outputs)\n",
        "            top1 = output.argmax(1).item()\n",
        "            if top1 == tgt_vocab['<eos>']:\n",
        "                break\n",
        "            result_ids.append(top1)\n",
        "            input_token = torch.tensor([top1]).to(device)\n",
        "\n",
        "    translated = [tgt_itos[idx] for idx in result_ids]\n",
        "    return ' '.join(translated)\n",
        "\n",
        "# 🔄 Example usage:\n",
        "while True:\n",
        "    input_text = input(\"🔤 Enter an English sentence (or type 'exit' to quit): \")\n",
        "    if input_text.lower() == 'exit':\n",
        "        break\n",
        "    translation = translate_sentence(model, input_text, SRC_stoi, TGT_stoi, TGT_itos)\n",
        "    print(\"🌐 Assamese:\", translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "igQm-83PxmJ0",
        "outputId": "740e4809-7c41-49fa-b6b0-405ba71c8a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔤 Enter an English sentence (or type 'exit' to quit): Hello\n",
            "🌐 Assamese: স্কঃ কলিয়াবৰত এটা দিনত দিয়াৰ লগতে সত্ৰীয়া বশিষ্ঠ দেৱ গৰাকীৰ বিৰুদ্ধে শূন্য কৰি\n",
            "🔤 Enter an English sentence (or type 'exit' to quit): My name is\n",
            "🌐 Assamese: মোৰ ৰাম নাথ কোবিন্দৰ পৰা মোৰ সাধাৰণ সম্পাদক লুৰিণজ্যোতি গগৈয়ে মোৰ শিৰ দোঁ খাই\n",
            "🔤 Enter an English sentence (or type 'exit' to quit): My name is Pratiksha\n",
            "🌐 Assamese: মোৰ ৰাম নাথ মোৰ তেওঁলৈ প্ৰৱেশত দি এনেদৰে মই মোৰ উপায়ুক্ত আৰু\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-17-1136676662.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 🔄 Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔤 Enter an English sentence (or type 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}